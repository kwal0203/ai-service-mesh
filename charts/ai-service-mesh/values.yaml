namespace: ai-mesh

image:
  pullPolicy: IfNotPresent

gateway:
  requestTimeoutSeconds: 300

mesh:
  enabled: true
  inject: enabled
  proxyResources:
    cpuRequest: 10m
    cpuLimit: 50m

ingress:
  enabled: true
  className: nginx
  host: ai-mesh.local

resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

hpa:
  enabled: true
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 70

resourceIsolation:
  enabled: false
  quota:
    pods: "12"
    requestsCpu: "2"
    requestsMemory: "4Gi"
    limitsCpu: "4"
    limitsMemory: "8Gi"
  limitRange:
    default:
      cpu: 500m
      memory: 512Mi
    defaultRequest:
      cpu: 100m
      memory: 256Mi

networkPolicy:
  enabled: false
  allowIngressFromNamespaces: []

services:
  - name: gateway
    image: ai-mesh/gateway:0.1.0
    port: 8000
    path: /
  - name: embedding
    image: ai-mesh/embedding:0.1.0
    port: 8001
    path: /embedding
  - name: classifier
    image: ai-mesh/classifier:0.1.0
    port: 8002
    path: /classifier
  - name: eval
    image: ai-mesh/eval:0.1.0
    port: 8003
    path: /eval
  - name: llm
    image: ai-mesh/llm:0.1.0
    port: 8004
    path: /generate
  - name: vision
    image: ai-mesh/vision:0.1.0
    port: 8005
    path: /classify-image

canaryServices: []

trafficSplit:
  enabled: false
  service: classifier
  port: 8002
  backends:
    - name: classifier-stable
      serviceSuffix: classifier
      port: 8002
      weight: 90
    - name: classifier-canary
      serviceSuffix: classifier-canary
      port: 8002
      weight: 10
